from flask import Flask, request, jsonify
from flask_cors import CORS
import subprocess
import os
import uuid
import whisper
import openai
from dotenv import load_dotenv
from pathlib import Path
import re
import nltk
nltk.download('punkt', quiet=True)
from nltk.tokenize import sent_tokenize


load_dotenv(dotenv_path=Path("secret.env").resolve())
openai.api_key = os.getenv("OPENAI_API_KEY")

app = Flask(__name__)
CORS(app, resources={r"/analyze": {"origins": "*"}}, methods=["GET", "POST", "OPTIONS"], allow_headers=["Content-Type"])
model = whisper.load_model("large")  # ××¤×©×¨ ×’× tiny ××• base ×× ××ª×” ×¨×•×¦×” ×©×–×” ×™×”×™×” ××”×™×¨

@app.route("/analyze", methods=["OPTIONS"])
def analyze_options():
    return '', 200

@app.route("/analyze", methods=["POST"])
def analyze():

    data = request.get_json()
    url = data.get("url")

    if not url:
        return jsonify({"error": "Missing URL"}), 400

    print("ğŸ“¥ URL ×©×”×ª×§×‘×œ:", url)

    # ×©× ×–×× ×™ ×œ×§×•×‘×¥
    filename = f"audio_{uuid.uuid4()}.mp3"

    try:
        print("â¬‡ï¸ ××•×¨×™×“ ××•×“×™×• ××”×¡×¨×˜×•×Ÿ ×¢× yt-dlp...")
        print("âœ… yt-dlp path:", subprocess.run(["which", "yt-dlp"], capture_output=True, text=True).stdout.strip())
        # ×©×œ×‘ 1: ×”×•×¨×“ ××•×“×™×• ××”×¡×¨×˜×•×Ÿ
        command = [
            "yt-dlp",
            "-x", "--audio-format", "mp3",
            url,
            "-o", filename
        ]
        subprocess.run(command, check=True)

        print("âœ… ×”×•×¨×“×ª ×”××•×“×™×• ×”×¡×ª×™×™××”:", filename)

        print("ğŸ§  ××¨×™×¥ ×ª××œ×•×œ ×¢× whisper...")
        # ×©×œ×‘ 2: ×ª××œ×•×œ ×¢× whisper
        result = model.transcribe(filename, language="he")
        text = result["text"]

        # ×©×œ×‘ ×‘×™× ×™×™×: × ×™×§×•×™ ×•×¤×™×©×•×˜ ×˜×§×¡×˜
        def gpt_clean_text(text):
            try:
                response = openai.ChatCompletion.create(
                    model="gpt-4-turbo",
                    messages=[
                        {"role": "system", "content": "××ª×” ×× ×§×” ×˜×§×¡×˜×™× ×§×œ×•×§×œ×™× ×•××¤×©×˜ × ×™×¡×•×—×™× ×›×“×™ ×©×™×”×™×” × ×™×ª×Ÿ ×œ×”×‘×™×Ÿ ×•×œ× ×ª×— ××•×ª×. ×”×¤×œ×˜ ×©×œ×š ×¦×¨×™×š ×œ×”×™×•×ª ×˜×§×¡×˜ ×‘×¨×•×¨, ×ª××¦×™×ª×™ ×•×œ×œ× ×©×’×™××•×ª ×œ×©×•× ×™×•×ª ××• ×ª×—×‘×™×¨×™×•×ª."},
                        {"role": "user", "content": f"×¤×©×˜ ××ª ×”×˜×§×¡×˜ ×”×‘× ×›×š ×©×™×”×™×” ×‘×¨×•×¨ ×•×§×¨×™× ×™×•×ª×¨:\n{text}"}
                    ],
                    temperature=0.3
                )
                return response.choices[0].message.content.strip()
            except Exception as e:
                print("âŒ ×©×’×™××” ×‘×¤×™×©×•×˜ ×”×˜×§×¡×˜:", e)
                return text  # ×× × ×›×©×œ, × ××©×™×š ×¢× ×”×˜×§×¡×˜ ×”××§×•×¨×™

        def check_text_with_gpt(text):
            text = gpt_clean_text(text)
            split_response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",  # ××• gpt-4 ×× ×™×© ×œ×š ×’×™×©×”
                messages=[
                    {"role": "system", "content": "××ª×” ×¢×•×–×¨ NLP. ×—×œ×§ ×˜×§×¡×˜ ×œ×˜×¢× ×•×ª × ×¤×¨×“×•×ª. ×›×œ ×˜×¢× ×” ×‘×©×•×¨×” ×—×“×©×” ×‘×œ×‘×“."},
                    {"role": "user", "content": f"×—×œ×§ ××ª ×”×˜×§×¡×˜ ×”×‘× ×œ×˜×¢× ×•×ª × ×¤×¨×“×•×ª. ×›×œ ×˜×¢× ×” ×¦×¨×™×›×” ×œ×”×™×•×ª ×§×¦×¨×” ×•×××•×§×“×ª:\n{text}"}
                ],
                temperature=0.3
            )
            claims = [line.strip() for line in split_response.choices[0].message.content.strip().split('\n') if line.strip()]

            answers = []
            for claim in claims:
                try:
                    response = openai.ChatCompletion.create(
                        model="gpt-3.5-turbo",  # ××• gpt-4 ×× ×™×© ×œ×š ×’×™×©×”
                        messages=[
                            {"role": "system", "content": "××ª×” ×‘×•×“×§ ×¢×•×‘×“×•×ª ××“×•×™×§. ×§×‘×œ ×˜×¢× ×” ×•×¢× ×” ×”×× ×”×™× × ×›×•× ×” ××• ×©×’×•×™×”, ×•×œ××”."},
                            {"role": "user", "content": f"×”×× ×”××©×¤×˜ ×”×‘× × ×›×•×Ÿ ××• ×©×’×•×™? ×¢× ×” ×¨×§ '× ×›×•×Ÿ' ××• '×©×’×•×™' ×•×œ××—×¨ ××›×Ÿ ×”×¡×‘×¨ ××“×•×¢:\n\"{claim}\""}
                        ],
                        temperature=0.2
                    )
                    answer_text = response.choices[0].message.content.strip()
                    verdict = "unknown"
                    if any(keyword in answer_text.lower() for keyword in ["× ×›×•×Ÿ", "××“×•×™×§", "×××™×ª×™", "×ª×§×£"]):
                        verdict = "true"
                    elif any(keyword in answer_text.lower() for keyword in ["×©×’×•×™", "×œ× × ×›×•×Ÿ", "×œ× ××“×•×™×§", "×œ× ×ª×§×£"]):
                        verdict = "false"

                    answers.append({
                        "claim": claim,
                        "verdict": verdict,
                        "gpt_answer": answer_text
                    })
                except Exception as e:
                    answers.append({
                        "claim": claim,
                        "verdict": "unknown",
                        "gpt_answer": f"×©×’×™××” ×‘×‘×“×™×§×”: {str(e)}"
                    })

            return answers

        print("ğŸ“ ×ª××œ×•×œ ×©×”×ª×§×‘×œ:", text)

        # ×‘×“×™×§×ª GPT ××—×¨×™ ×”×ª××œ×•×œ
        gpt_analysis = check_text_with_gpt(text)

        # ×”×—×–×¨ ××ª ×”×ª×•×¦××”
        return jsonify({
            "verdict": "×ª××œ×•×œ ×”×•×©×œ×",
            "reason": text,
            "gpt_analysis": gpt_analysis  # ×¢×›×©×™×• ×–×• ×¨×©×™××ª ×˜×¢× ×•×ª ×¢× × ×™×ª×•×—×™×
        })

    except Exception as e:
        print("âŒ ×©×’×™××”:", e)
        return jsonify({"error": str(e)}), 500
    finally:
        # ××—×§ ××ª ×”×§×•×‘×¥
        if os.path.exists(filename):
            os.remove(filename)

if __name__ == "__main__":
    app.run(port=5100, debug=True)